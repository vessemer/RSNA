{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: albumentations in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from albumentations) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: imgaug>=0.2.5 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from albumentations) (0.2.6)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from albumentations) (3.4.2.17)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from albumentations) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from imgaug>=0.2.5->albumentations) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from imgaug>=0.2.5->albumentations) (0.14.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=1.8 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (2.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (5.2.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: dask[array]>=0.9.0 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (0.19.2)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.1 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (0.5.5)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.1.0 in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.7.3; extra == \"array\" in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from dask[array]>=0.9.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug>=0.2.5->albumentations) (40.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !conda info dask-core==0.19.1=py36_0\n",
    "# !conda info opencv==3.4.1=py36h6fd60c2_2\n",
    "# !which pip\n",
    "! /home/vessemer/anaconda3/envs/cxr/bin/pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - albumentations\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/auto/linux-64\n",
      "  - https://conda.anaconda.org/auto/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path.append('/home/vessemer/faster-rcnn.pytorch/lib/')\n",
    "# !conda install --yes --prefix {sys.prefix} pytorch=0.4.0\n",
    "# !conda install --yes --prefix {sys.prefix} -c auto albumentations #easydict #cython cffi scipy matplotlib pyyaml\n",
    "# opencv-python\n",
    "# easydict\n",
    "# tensorboardX\n",
    "# msgpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampler(Sampler):\n",
    "    def __init__(self, train_size, batch_size):\n",
    "        self.num_data = train_size\n",
    "        self.num_per_batch = int(train_size / batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.range = torch.arange(0,batch_size).view(1, batch_size).long()\n",
    "        self.leftover_flag = False\n",
    "        if train_size % batch_size:\n",
    "            self.leftover = torch.arange(self.num_per_batch*batch_size, train_size).long()\n",
    "            self.leftover_flag = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_num = torch.randperm(self.num_per_batch).view(-1,1) * self.batch_size\n",
    "        self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "        self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "        if self.leftover_flag:\n",
    "            self.rand_num_view = torch.cat((self.rand_num_view, self.leftover),0)\n",
    "\n",
    "        return iter(self.rand_num_view)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "# if args.dataset == \"pascal_voc\":\n",
    "args = easydict.EasyDict()\n",
    "args.imdb_name = \"voc_2007_trainval\"\n",
    "args.imdbval_name = \"voc_2007_test\"\n",
    "args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '3']\n",
    "\n",
    "args.large_scale = True\n",
    "args.cuda = True\n",
    "args.net = 'res101'\n",
    "args.cfg_file = \"cfgs/{}_ls.yml\".format(args.net) if args.large_scale else \"cfgs/{}.yml\".format(args.net)\n",
    "\n",
    "# if args.cfg_file is not None:\n",
    "#     cfg_from_file(args.cfg_file)\n",
    "# if args.set_cfgs is not None:\n",
    "#     cfg_from_list(args.set_cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      " 'ANCHOR_SCALES': [8, 16, 32],\n",
      " 'CROP_RESIZE_WITH_MAX_POOL': True,\n",
      " 'CUDA': False,\n",
      " 'DATA_DIR': '/home/vessemer/faster-rcnn.pytorch/data',\n",
      " 'DEDUP_BOXES': 0.0625,\n",
      " 'EPS': 1e-14,\n",
      " 'EXP_DIR': 'default',\n",
      " 'FEAT_STRIDE': [16],\n",
      " 'GPU_ID': 0,\n",
      " 'MATLAB': 'matlab',\n",
      " 'MAX_NUM_GT_BOXES': 20,\n",
      " 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,\n",
      "               'FIXED_LAYERS': 5,\n",
      "               'REGU_DEPTH': False,\n",
      "               'WEIGHT_DECAY': 4e-05},\n",
      " 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),\n",
      " 'POOLING_MODE': 'crop',\n",
      " 'POOLING_SIZE': 7,\n",
      " 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},\n",
      " 'RNG_SEED': 3,\n",
      " 'ROOT_DIR': '/home/vessemer/faster-rcnn.pytorch',\n",
      " 'TEST': {'BBOX_REG': True,\n",
      "          'HAS_RPN': False,\n",
      "          'MAX_SIZE': 1000,\n",
      "          'MODE': 'nms',\n",
      "          'NMS': 0.3,\n",
      "          'PROPOSAL_METHOD': 'gt',\n",
      "          'RPN_MIN_SIZE': 16,\n",
      "          'RPN_NMS_THRESH': 0.7,\n",
      "          'RPN_POST_NMS_TOP_N': 300,\n",
      "          'RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'RPN_TOP_N': 5000,\n",
      "          'SCALES': [600],\n",
      "          'SVM': False},\n",
      " 'TRAIN': {'ASPECT_GROUPING': False,\n",
      "           'BATCH_SIZE': 128,\n",
      "           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],\n",
      "           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],\n",
      "           'BBOX_NORMALIZE_TARGETS': True,\n",
      "           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,\n",
      "           'BBOX_REG': True,\n",
      "           'BBOX_THRESH': 0.5,\n",
      "           'BG_THRESH_HI': 0.5,\n",
      "           'BG_THRESH_LO': 0.1,\n",
      "           'BIAS_DECAY': False,\n",
      "           'BN_TRAIN': False,\n",
      "           'DISPLAY': 10,\n",
      "           'DOUBLE_BIAS': True,\n",
      "           'FG_FRACTION': 0.25,\n",
      "           'FG_THRESH': 0.5,\n",
      "           'GAMMA': 0.1,\n",
      "           'HAS_RPN': True,\n",
      "           'IMS_PER_BATCH': 1,\n",
      "           'LEARNING_RATE': 0.001,\n",
      "           'MAX_SIZE': 1000,\n",
      "           'MOMENTUM': 0.9,\n",
      "           'PROPOSAL_METHOD': 'gt',\n",
      "           'RPN_BATCHSIZE': 256,\n",
      "           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'RPN_CLOBBER_POSITIVES': False,\n",
      "           'RPN_FG_FRACTION': 0.5,\n",
      "           'RPN_MIN_SIZE': 8,\n",
      "           'RPN_NEGATIVE_OVERLAP': 0.3,\n",
      "           'RPN_NMS_THRESH': 0.7,\n",
      "           'RPN_POSITIVE_OVERLAP': 0.7,\n",
      "           'RPN_POSITIVE_WEIGHT': -1.0,\n",
      "           'RPN_POST_NMS_TOP_N': 2000,\n",
      "           'RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SCALES': [600],\n",
      "           'SNAPSHOT_ITERS': 5000,\n",
      "           'SNAPSHOT_KEPT': 3,\n",
      "           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',\n",
      "           'STEPSIZE': [30000],\n",
      "           'SUMMARY_INTERVAL': 180,\n",
      "           'TRIM_HEIGHT': 600,\n",
      "           'TRIM_WIDTH': 600,\n",
      "           'TRUNCATED': False,\n",
      "           'USE_ALL_GT': True,\n",
      "           'USE_FLIPPED': True,\n",
      "           'USE_GT': False,\n",
      "           'WEIGHT_DECAY': 0.0005},\n",
      " 'USE_GPU_NMS': True}\n"
     ]
    }
   ],
   "source": [
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "np.random.seed(cfg.RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() and not args.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Path does not exist: /home/vessemer/faster-rcnn.pytorch/data/VOCdevkit2007/VOC2007/ImageSets/Main/trainval.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-a9649f176659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_FLIPPED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_GPU_NMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroidb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_roidb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroidb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/roi_data_layer/roidb.py\u001b[0m in \u001b[0;36mcombined_roidb\u001b[0;34m(imdb_names, training)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroidb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0mroidbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_roidb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimdb_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0mroidb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroidbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/roi_data_layer/roidb.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroidb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0mroidbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_roidb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimdb_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0mroidb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroidbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/roi_data_layer/roidb.py\u001b[0m in \u001b[0;36mget_roidb\u001b[0;34m(imdb_name)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_roidb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_imdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded dataset `{:s}` for training'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_proposal_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROPOSAL_METHOD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/datasets/factory.py\u001b[0m in \u001b[0;36mget_imdb\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown dataset: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m__sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/datasets/factory.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(split, year)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'voc_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0m__sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Set up coco_2014_<split>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/datasets/pascal_voc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_set, year, devkit_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_image_set_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Default to roidb handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# self._roidb_handler = self.selective_search_roidb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/faster-rcnn.pytorch/lib/datasets/pascal_voc.py\u001b[0m in \u001b[0;36m_load_image_set_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m                                       self._image_set + '.txt')\n\u001b[1;32m    106\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_set_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;34m'Path does not exist: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_set_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_set_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mimage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Path does not exist: /home/vessemer/faster-rcnn.pytorch/data/VOCdevkit2007/VOC2007/ImageSets/Main/trainval.txt"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "# -- Note: Use validation set and disable the flipped to enable faster loading.\n",
    "cfg.TRAIN.USE_FLIPPED = True\n",
    "cfg.USE_GPU_NMS = args.cuda\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb(args.imdb_name)\n",
    "train_size = len(roidb)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "# output_dir = args.save_dir + \"/\" + args.net + \"/\" + args.dataset\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# sampler_batch = sampler(train_size, args.batch_size)\n",
    "\n",
    "# dataset = roibatchLoader(roidb, ratio_list, ratio_index, args.batch_size, \\\n",
    "#                        imdb.num_classes, training=True)\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "#                         sampler=sampler_batch, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  parser = argparse.ArgumentParser(description='Train a Fast R-CNN network')\n",
    "  parser.add_argument('--dataset', dest='dataset',\n",
    "                      help='training dataset',\n",
    "                      default='pascal_voc', type=str)\n",
    "  parser.add_argument('--net', dest='net',\n",
    "                    help='vgg16, res101',\n",
    "                    default='vgg16', type=str)\n",
    "  parser.add_argument('--start_epoch', dest='start_epoch',\n",
    "                      help='starting epoch',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--epochs', dest='max_epochs',\n",
    "                      help='number of epochs to train',\n",
    "                      default=20, type=int)\n",
    "  parser.add_argument('--disp_interval', dest='disp_interval',\n",
    "                      help='number of iterations to display',\n",
    "                      default=100, type=int)\n",
    "  parser.add_argument('--checkpoint_interval', dest='checkpoint_interval',\n",
    "                      help='number of iterations to display',\n",
    "                      default=10000, type=int)\n",
    "\n",
    "  parser.add_argument('--save_dir', dest='save_dir',\n",
    "                      help='directory to save models', default=\"models\",\n",
    "                      type=str)\n",
    "  parser.add_argument('--nw', dest='num_workers',\n",
    "                      help='number of worker to load data',\n",
    "                      default=0, type=int)\n",
    "  parser.add_argument('--cuda', dest='cuda',\n",
    "                      help='whether use CUDA',\n",
    "                      action='store_true')\n",
    "  parser.add_argument('--ls', dest='large_scale',\n",
    "                      help='whether use large imag scale',\n",
    "                      action='store_true')                      \n",
    "  parser.add_argument('--mGPUs', dest='mGPUs',\n",
    "                      help='whether use multiple GPUs',\n",
    "                      action='store_true')\n",
    "  parser.add_argument('--bs', dest='batch_size',\n",
    "                      help='batch_size',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--cag', dest='class_agnostic',\n",
    "                      help='whether perform class_agnostic bbox regression',\n",
    "                      action='store_true')\n",
    "\n",
    "# config optimization\n",
    "  parser.add_argument('--o', dest='optimizer',\n",
    "                      help='training optimizer',\n",
    "                      default=\"sgd\", type=str)\n",
    "  parser.add_argument('--lr', dest='lr',\n",
    "                      help='starting learning rate',\n",
    "                      default=0.001, type=float)\n",
    "  parser.add_argument('--lr_decay_step', dest='lr_decay_step',\n",
    "                      help='step to do learning rate decay, unit is epoch',\n",
    "                      default=5, type=int)\n",
    "  parser.add_argument('--lr_decay_gamma', dest='lr_decay_gamma',\n",
    "                      help='learning rate decay ratio',\n",
    "                      default=0.1, type=float)\n",
    "\n",
    "# set training session\n",
    "  parser.add_argument('--s', dest='session',\n",
    "                      help='training session',\n",
    "                      default=1, type=int)\n",
    "\n",
    "# resume trained model\n",
    "  parser.add_argument('--r', dest='resume',\n",
    "                      help='resume checkpoint or not',\n",
    "                      default=False, type=bool)\n",
    "  parser.add_argument('--checksession', dest='checksession',\n",
    "                      help='checksession to load model',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--checkepoch', dest='checkepoch',\n",
    "                      help='checkepoch to load model',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--checkpoint', dest='checkpoint',\n",
    "                      help='checkpoint to load model',\n",
    "                      default=0, type=int)\n",
    "# log and diaplay\n",
    "  parser.add_argument('--use_tfb', dest='use_tfboard',\n",
    "                      help='whether use tensorboard',\n",
    "                      action='store_true')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python36.zip',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python3.6',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python3.6/lib-dynload',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg',\n",
       " '/home/vessemer/anaconda3/envs/cxr/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/vessemer/.ipython',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "  # initilize the tensor holder here.\n",
    "  im_data = torch.FloatTensor(1)\n",
    "  im_info = torch.FloatTensor(1)\n",
    "  num_boxes = torch.LongTensor(1)\n",
    "  gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "  # ship to cuda\n",
    "  if args.cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "  # make variable\n",
    "  im_data = Variable(im_data)\n",
    "  im_info = Variable(im_info)\n",
    "  num_boxes = Variable(num_boxes)\n",
    "  gt_boxes = Variable(gt_boxes)\n",
    "\n",
    "  if args.cuda:\n",
    "    cfg.CUDA = True\n",
    "\n",
    "  # initilize the network here.\n",
    "  if args.net == 'vgg16':\n",
    "    fasterRCNN = vgg16(imdb.classes, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  elif args.net == 'res101':\n",
    "    fasterRCNN = resnet(imdb.classes, 101, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  elif args.net == 'res50':\n",
    "    fasterRCNN = resnet(imdb.classes, 50, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  elif args.net == 'res152':\n",
    "    fasterRCNN = resnet(imdb.classes, 152, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  else:\n",
    "    print(\"network is not defined\")\n",
    "    pdb.set_trace()\n",
    "\n",
    "  fasterRCNN.create_architecture()\n",
    "\n",
    "  lr = cfg.TRAIN.LEARNING_RATE\n",
    "  lr = args.lr\n",
    "  #tr_momentum = cfg.TRAIN.MOMENTUM\n",
    "  #tr_momentum = args.momentum\n",
    "\n",
    "  params = []\n",
    "  for key, value in dict(fasterRCNN.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "      if 'bias' in key:\n",
    "        params += [{'params':[value],'lr':lr*(cfg.TRAIN.DOUBLE_BIAS + 1), \\\n",
    "                'weight_decay': cfg.TRAIN.BIAS_DECAY and cfg.TRAIN.WEIGHT_DECAY or 0}]\n",
    "      else:\n",
    "        params += [{'params':[value],'lr':lr, 'weight_decay': cfg.TRAIN.WEIGHT_DECAY}]\n",
    "\n",
    "  if args.optimizer == \"adam\":\n",
    "    lr = lr * 0.1\n",
    "    optimizer = torch.optim.Adam(params)\n",
    "\n",
    "  elif args.optimizer == \"sgd\":\n",
    "    optimizer = torch.optim.SGD(params, momentum=cfg.TRAIN.MOMENTUM)\n",
    "\n",
    "  if args.resume:\n",
    "    load_name = os.path.join(output_dir,\n",
    "      'faster_rcnn_{}_{}_{}.pth'.format(args.checksession, args.checkepoch, args.checkpoint))\n",
    "    print(\"loading checkpoint %s\" % (load_name))\n",
    "    checkpoint = torch.load(load_name)\n",
    "    args.session = checkpoint['session']\n",
    "    args.start_epoch = checkpoint['epoch']\n",
    "    fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if 'pooling_mode' in checkpoint.keys():\n",
    "      cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "    print(\"loaded checkpoint %s\" % (load_name))\n",
    "\n",
    "  if args.mGPUs:\n",
    "    fasterRCNN = nn.DataParallel(fasterRCNN)\n",
    "\n",
    "  if args.cuda:\n",
    "    fasterRCNN.cuda()\n",
    "\n",
    "  iters_per_epoch = int(train_size / args.batch_size)\n",
    "\n",
    "  if args.use_tfboard:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    logger = SummaryWriter(\"logs\")\n",
    "\n",
    "  for epoch in range(args.start_epoch, args.max_epochs + 1):\n",
    "    # setting to train mode\n",
    "    fasterRCNN.train()\n",
    "    loss_temp = 0\n",
    "    start = time.time()\n",
    "\n",
    "    if epoch % (args.lr_decay_step + 1) == 0:\n",
    "        adjust_learning_rate(optimizer, args.lr_decay_gamma)\n",
    "        lr *= args.lr_decay_gamma\n",
    "\n",
    "    data_iter = iter(dataloader)\n",
    "    for step in range(iters_per_epoch):\n",
    "      data = next(data_iter)\n",
    "      im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "      im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "      gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "      num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "      fasterRCNN.zero_grad()\n",
    "      rois, cls_prob, bbox_pred, \\\n",
    "      rpn_loss_cls, rpn_loss_box, \\\n",
    "      RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "      rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "      loss = rpn_loss_cls.mean() + rpn_loss_box.mean() \\\n",
    "           + RCNN_loss_cls.mean() + RCNN_loss_bbox.mean()\n",
    "      loss_temp += loss.item()\n",
    "\n",
    "      # backward\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      if args.net == \"vgg16\":\n",
    "          clip_gradient(fasterRCNN, 10.)\n",
    "      optimizer.step()\n",
    "\n",
    "      if step % args.disp_interval == 0:\n",
    "        end = time.time()\n",
    "        if step > 0:\n",
    "          loss_temp /= (args.disp_interval + 1)\n",
    "\n",
    "        if args.mGPUs:\n",
    "          loss_rpn_cls = rpn_loss_cls.mean().item()\n",
    "          loss_rpn_box = rpn_loss_box.mean().item()\n",
    "          loss_rcnn_cls = RCNN_loss_cls.mean().item()\n",
    "          loss_rcnn_box = RCNN_loss_bbox.mean().item()\n",
    "          fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "          bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "        else:\n",
    "          loss_rpn_cls = rpn_loss_cls.item()\n",
    "          loss_rpn_box = rpn_loss_box.item()\n",
    "          loss_rcnn_cls = RCNN_loss_cls.item()\n",
    "          loss_rcnn_box = RCNN_loss_bbox.item()\n",
    "          fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "          bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "\n",
    "        print(\"[session %d][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" \\\n",
    "                                % (args.session, epoch, step, iters_per_epoch, loss_temp, lr))\n",
    "        print(\"\\t\\t\\tfg/bg=(%d/%d), time cost: %f\" % (fg_cnt, bg_cnt, end-start))\n",
    "        print(\"\\t\\t\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box %.4f\" \\\n",
    "                      % (loss_rpn_cls, loss_rpn_box, loss_rcnn_cls, loss_rcnn_box))\n",
    "        if args.use_tfboard:\n",
    "          info = {\n",
    "            'loss': loss_temp,\n",
    "            'loss_rpn_cls': loss_rpn_cls,\n",
    "            'loss_rpn_box': loss_rpn_box,\n",
    "            'loss_rcnn_cls': loss_rcnn_cls,\n",
    "            'loss_rcnn_box': loss_rcnn_box\n",
    "          }\n",
    "          logger.add_scalars(\"logs_s_{}/losses\".format(args.session), info, (epoch - 1) * iters_per_epoch + step)\n",
    "\n",
    "        loss_temp = 0\n",
    "        start = time.time()\n",
    "\n",
    "    \n",
    "    save_name = os.path.join(output_dir, 'faster_rcnn_{}_{}_{}.pth'.format(args.session, epoch, step))\n",
    "    save_checkpoint({\n",
    "      'session': args.session,\n",
    "      'epoch': epoch + 1,\n",
    "      'model': fasterRCNN.module.state_dict() if args.mGPUs else fasterRCNN.state_dict(),\n",
    "      'optimizer': optimizer.state_dict(),\n",
    "      'pooling_mode': cfg.POOLING_MODE,\n",
    "      'class_agnostic': args.class_agnostic,\n",
    "    }, save_name)\n",
    "    print('save model: {}'.format(save_name))\n",
    "\n",
    "  if args.use_tfboard:\n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e79b58937890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/vessemer/faster-rcnn.pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
